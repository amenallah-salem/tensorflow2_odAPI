models_dict=[
  {'CenterNet HourGlass104 512x512' : 'http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_512x512_coco17_tpu-8.tar.gz'	},
  {'CenterNet HourGlass104 Keypoints 512x512' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_512x512_kpts_coco17_tpu-32.tar.gz'},
  {'CenterNet HourGlass104 1024x1024' : 'http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_1024x1024_coco17_tpu-32.tar.gz'},
  {'CenterNet HourGlass104 Keypoints 1024x1024' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_1024x1024_kpts_coco17_tpu-32.tar.gz'},
  {'CenterNet Resnet50 V1 FPN 512x512' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v1_fpn_512x512_coco17_tpu-8.tar.gz'},
  {'CenterNet Resnet50 V1 FPN Keypoints 512x512'	: 'http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8.tar.gz' },
  {'CenterNet Resnet101 V1 FPN 512x512' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8.tar.gz'},
  {'CenterNet Resnet50 V2 512x512' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v2_512x512_coco17_tpu-8.tar.gz'},
  {'CenterNet Resnet50 V2 Keypoints 512x512' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v2_512x512_kpts_coco17_tpu-8.tar.gz'},
  {'EfficientDet D0 512x512': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz'},
  {'EfficientDet D1 640x640' :'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz'},
  {'EfficientDet D2 768x768':'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz'},
  {'EfficientDet D3 896x896':	'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d3_coco17_tpu-32.tar.gz'},
  {'EfficientDet D4 1024x1024':'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d4_coco17_tpu-32.tar.gz'},
  {'EfficientDet D5 1280x1280':'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d6_coco17_tpu-32.tar.gz'},
  {'EfficientDet D6 1280x1280':'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d6_coco17_tpu-32.tar.gz'},
  {'EfficientDet D7 1536x1536':'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d7_coco17_tpu-32.tar.gz'},
  {'SSD MobileNet v2 320x320':'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz'},
  {'SSD MobileNet V1 FPN 640x640':'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz'},
  {'SSD MobileNet V2 FPNLite 320x320':'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'},
  {'SSD MobileNet V2 FPNLite 640x640':'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'},
  {'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'},
  {'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz'},
  {'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz' },
  {'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz'},
  {'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.tar.gz'},
  {'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.tar.gz'},
  {'Faster R-CNN ResNet50 V1 640x640' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz'},
  {'Faster R-CNN ResNet50 V1 1024x1024': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.tar.gz'},
  {'Faster R-CNN ResNet50 V1 800x1333': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.tar.gz'},
  {'Faster R-CNN ResNet101 V1 640x640' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz'},
  {'Faster R-CNN ResNet101 V1 1024x1024': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz'},
  {'Faster R-CNN ResNet101 V1 800x1333' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8.tar.gz'},
  {'Faster R-CNN ResNet152 V1 640x640' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz'},
  {'Faster R-CNN ResNet152 V1 1024x1024' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz'},
  {'Faster R-CNN ResNet152 V1 800x1333' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8.tar.gz'},
  {'Faster R-CNN Inception ResNet V2 640x640': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz'},
  {'Faster R-CNN Inception ResNet V2 1024x1024' :'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz'},
  {'Mask R-CNN Inception ResNet V2 1024x1024': 'http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz'}
]


def disp_models_names():
  print("please chose a model to train it:\n")
  for model_cfg in models_dict:
    for key, value in model_cfg.items() :
      print (key)

def download_model(destination):
  model_name =input('Enter model name:\n')
  for model_cfg in models_dict:
    for key, value in model_cfg.items() :
      if key == model_name:
        url = value
        downloaded_name_file = value.split('/')[-1]
      else:
        pass
  model_link_to_download = url 
  wget.download(url, destination)

  return model_name, downloaded_name_file

def update_key_dic_cfg_yaml(main_dir, key_old_one, Value_old_one, new_one):
  with open(os.path.join(main_dir,"cfg.yaml")) as yamlfile:
    data = yaml.load(yamlfile, Loader=yaml.FullLoader)
    print(data)
    print("Reading cfg.yaml file successfully.")
    data[key_old_one][Value_old_one] = new_one
     
    yamlfile.close()

def update_key_val_cfg_yaml(main_dir, key_old_one, value_new_one):
  with open(os.path.join(main_dir,"cfg.yaml")) as yamlfile:
    data = yaml.load(yamlfile, Loader=yaml.FullLoader)
    print(data)
    print("Updating cfg.yaml file successful.")
    data[key_old_one][Value_old_one] = new_one
     
    yamlfile.close()


def read_config():
    pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          
    with tf.io.gfile.GFile(MODEL_DIR, "r") as f:                                                                                                                                                                                                                     
        proto_str = f.read()                                                                                                                                                                                                                                          
        text_format.Merge(proto_str, pipeline)
        print('Reading pipeline.config file successfully.')
    return pipeline

def write_config(pipeline):
    config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        
    with tf.io.gfile.GFile(MODEL_DIR, "wb") as f:  
        print("Writing costum config successfully.")                                                                                                                                                                                                                     
        f.write(config_text)

def modify_config(pipeline):
    print(100*'0')
    print("Start editing pretrained model config : ", model_file_name)
    print(100*'0')

    if model_file_name.startswith('efficientdet',0):
      pipeline.model.ssd.num_classes = data['num_classes']

    if model_file_name.startswith('ssd',0):
      pipeline.model.ssd.num_classes = data['num_classes']
    elif model_file_name.startswith('centernet',0):
      pipeline.model.center_net.num_classes = data['num_classes']
    elif model_file_name.startswith('faster',0):
      pipeline.model.faster_rcnn.num_classes = data['num_classes']
    elif model_file_name.startswith('mask',0):
      pipeline.model.faster_rcnn.num_classes = data['num_classes']

    else:
      print('model name is not confirmed: set it to None by default')
      print('please enter a valid model name--> breaking out ')





    
    pipeline.train_config.batch_size = data['batch_size']
    pipeline.train_config.fine_tune_checkpoint_type = data['fine_tune_checkpoint_type']
    pipeline.train_config.fine_tune_checkpoint = data['fine_tune_checkpoint']

    pipeline.train_input_reader.label_map_path = data["label_map_path"]
    pipeline.train_input_reader.tf_record_input_reader.input_path[0] = data['train_tf_record_input_path']

    pipeline.eval_input_reader[0].label_map_path = data["label_map_path"]
    pipeline.eval_input_reader[0].tf_record_input_reader.input_path[0] = data['test_tf_record_input_path']

    return pipeline
def setup_pipeline():
    pipeline = read_config()
    pipeline = modify_config(pipeline)
    write_config(pipeline)
    print("New configuration is set as follow: ")
    print(pipeline)


if __name__=="__main__":
  import wget 
  import xtarfile as tarfile 
  import os
  import shutil
  import yaml
  from pathlib import Path
  from google.protobuf import text_format
  from object_detection.protos import pipeline_pb2
  import tensorflow as tf


  destination=os.getcwd()#/content/al_obj_det/object_detection
  disp_models_names()#list of models disp
  model_name , downloaded_name_file = download_model(destination)
  #model_name= .tar.gz file , downloaded_name_file= name of the file without .tar.gz
  print('model have been successfylly downloader in main dir under the name {}.tar.gz'.format(model_name))
  print("unziping and untaring the model file ")
  print("Defined main_dir :", os.getcwd())#/content/al_obj_det/object_detection
  
  with tarfile.open(downloaded_name_file, 'r') as archive:
    archive.extractall()

  print("extracting tar.gz file successfylly")
  
  os.remove(downloaded_name_file)#removing .tar.gz file from repo
  print("Deleting the .tar.gz archive file")
  model_file_name = downloaded_name_file.split('.')[-3]
  print("Finishing model preparation, the model is saved under the final name model_file_name:", model_file_name)# final extracted file 
  print("updating cfg.yaml file...")

  def _red_config(yaml_dir):
    with open(os.path.join(yaml_dir, "cfg.yaml"), "r") as yamlfile:
      data = yaml.load(yamlfile, Loader=yaml.FullLoader)
    return data 

  data = _red_config("../")
  def yaml_dump(filepath_,data_):
    with open(filepath_,'w') as file_descriptor:
      yaml.dump(data, file_descriptor)
 
  data['model_main_directory'] = os.path.join(os.getcwd(), model_file_name)
  print(100 * '-')

  yaml_dump("../cfg.yaml",data)
  print('updated yaml file ')

  print(100 * '-')
  print('Start updating the model config file: {} in :{} file: '.format( 'pipeline.config', downloaded_name_file))
  downloaded_file = downloaded_name_file.split('.')[-3]#efficientdet_d1_coco17_tpu-32
  path_to_downloaded_file = os.path.join(os.getcwd(), downloaded_file)#get full path
  path_to_pipeline_config = os.path.join(path_to_downloaded_file, 'pipeline.config')
  fine_tune_checkpoint = os.path.join(path_to_downloaded_file, 'checkpoint/ckpt-0')
  MODEL_DIR = path_to_pipeline_config
  print(100 * '-')
  print("updating again the cfg.yaml file:\nwriting \n{\nnum_classes,\nfine_tune_checkpoint,\nfine_tune_checkpoint_type,\nlabel_map_path \ntf_record_input_reader\n}")
  data['fine_tune_checkpoint'] = fine_tune_checkpoint
  data['label_map_path'] = os.path.join(os.getcwd(), 'train_utils/label_map.pbtxt')
  data['train_tf_record_input_path'] = os.path.join(os.getcwd(),'train_utils/train.record' )
  data['test_tf_record_input_path'] = os.path.join(os.getcwd(),'train_utils/test.record' )
  data['pretrained_model_file_name'] = os.path.join(os.getcwd(), downloaded_file)
  data['dir_saved_model'] = os.path.join(os.getcwd(), 'inference_graph/frozen_graph/saved_model')

  yaml_dump("../cfg.yaml",data)
  setup_pipeline()
  print(100 * '-')
  print("Successfuly finishing updating pipeline configuration.")
